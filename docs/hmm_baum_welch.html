<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>HMM & Baum-Welch Explained — Comprehensive Guide</title>
  <link rel="stylesheet" href="style.css">
  <style>
    .concept { background:#f0f4ff; padding:12px; border-left:4px solid #0366d6; margin:12px 0; }
    .equation { background:#f7f7f7; padding:12px; font-family:monospace; margin:12px 0; overflow-x:auto; line-height:1.6; }
    .algorithm { background:#fffbf0; padding:12px; border-left:4px solid #d97706; margin:12px 0; }
    .example { background:#f0fdf4; padding:12px; border-left:4px solid #16a34a; margin:12px 0; }
    .warning { background:#fef2f2; padding:12px; border-left:4px solid #dc2626; margin:12px 0; }
    .small { font-size:0.95em; opacity:0.85; }
    table { width:100%; border-collapse:collapse; margin:12px 0; }
    table th, table td { border:1px solid #ddd; padding:10px; text-align:left; }
    table th { background:#f3f4f6; }
    code { background:#f7f7f7; padding:2px 6px; border-radius:3px; font-family:monospace; }
    .step { background:#e6f2ff; padding:10px; margin:8px 0; border-radius:4px; }
  </style>
</head>
<body>
<div class="container">
  <div class="nav"><a href="index.html">◀ Back</a></div>
  
  <h1>Hidden Markov Models & Baum-Welch: From Basics to Implementation</h1>
  <p class="note"><b>Goal:</b> Understand what HMMs are, how they work, why Baum-Welch algorithm trains them, and how it connects to the code in this project.</p>

  <!-- ==================== PART 1: INTRODUCTION ==================== -->
  <h2>Part 1: What is a Hidden Markov Model?</h2>

  <h3>1.1 The Markov Property (First Concept)</h3>
  <div class="concept">
    <b>Markov Property:</b> The future depends only on the present, not the past.
    <br><br>
    In other words: "Given the current state, the past is irrelevant."
    <br><br>
    <b>Example:</b> If you're at a restaurant today, tomorrow's restaurant choice depends on today (e.g., "avoid chains after restaurants"), not on what you ate last week.
  </div>

  <h3>1.2 A Simple Markov Chain (Not Hidden Yet)</h3>
  <div class="concept">
    <b>Markov Chain:</b> A sequence of states where you jump from one state to another with certain probabilities.
    <br><br>
    <b>Example: Weather Chain</b>
    <table>
      <tr><th>If today is...</th><th>Probability tomorrow is Sunny</th><th>Probability tomorrow is Rainy</th></tr>
      <tr><td>Sunny</td><td>0.8</td><td>0.2</td></tr>
      <tr><td>Rainy</td><td>0.4</td><td>0.6</td></tr>
    </table>
    This is a <b>Transition Matrix</b>: describes how likely you move from one state to another.
  </div>

  <div class="example">
    <b>Simulating a weather sequence:</b>
    <ol>
      <li>Start: Sunny</li>
      <li>Next: Random draw → 0.8 chance Sunny, 0.2 chance Rainy → Pick Sunny</li>
      <li>Next: From Sunny → 0.8 chance Sunny, 0.2 chance Rainy → Pick Rainy</li>
      <li>Next: From Rainy → 0.4 chance Sunny, 0.6 chance Rainy → Pick Rainy</li>
      <li>Sequence: Sunny → Sunny → Rainy → Rainy</li>
    </ol>
  </div>

  <h3>1.3 Why "Hidden" Markov Model?</h3>
  <div class="concept">
    <b>Regular Markov Chain:</b> You observe the state directly (e.g., you see if it's Sunny or Rainy).
    <br><br>
    <b>Hidden Markov Model:</b> You don't observe the state directly. Instead, you observe <b>emissions</b> (signals) generated by the hidden state.
    <br><br>
    <b>Example: Broken Weather Station</b>
    <ul>
      <li><b>Hidden state:</b> True weather (Sunny or Rainy) — you can't see this.</li>
      <li><b>Emission:</b> What the broken weather station displays (Sunny or Rainy prediction).</li>
      <li><b>Reality:</b> Station is 90% accurate when it's sunny (90% chance it shows "Sunny"), but only 60% accurate when it's rainy.</li>
    </ul>
    So even if the station shows "Sunny," you're not 100% sure it's actually sunny — there's a 10% chance it's rainy and the station got it wrong.
  </div>

  <h3>1.4 HMM Notation & Components</h3>
  <div class="equation">
    <b>An HMM has 5 components (λ = "lambda"):</b>
    <br><br>
    λ = (N, M, π, A, B)
    <br><br>
    <b>N:</b> Number of hidden states (e.g., 5 states for digit "3")
    <br>
    <b>M:</b> Number of possible observations/emissions (e.g., 32 symbols in codebook)
    <br>
    <b>π (pi):</b> Initial state probability — likelihood of starting in each state
    <br>
    <b>A:</b> State transition matrix — P(state_t | state_t-1)
    <br>
    <b>B:</b> Emission probability matrix — P(observation | state)
  </div>

  <div class="example">
    <b>Example: Digit Recognition HMM</b>
    <br><br>
    <b>N = 5:</b> We have 5 hidden states (could represent beginning, middle, end, etc. of the digit sound)
    <br>
    <b>M = 32:</b> Our codebook has 32 symbols (each MFCC frame gets quantized to one of 32 symbols)
    <br>
    <b>π:</b> <code>[0.95, 0.05, 0, 0, 0]</code> — Most likely start in state 1
    <br>
    <b>A:</b> 5×5 matrix — transitions between states
    <br>
    <b>B:</b> 5×32 matrix — each state can emit any of the 32 codebook symbols with some probability
  </div>

  <!-- ==================== PART 2: HMM OPERATIONS ==================== -->
  <h2>Part 2: Three Fundamental Problems (Operations)</h2>

  <h3>2.1 Problem 1: Evaluation (Forward Algorithm)</h3>
  <div class="concept">
    <b>Question:</b> Given an HMM and an observation sequence, what is the probability that the HMM generated this sequence?
    <br><br>
    <b>Application:</b> Classification. You have HMMs for digits 2, 3, 4, 5. You observe a sequence of codebook symbols. Which digit's HMM is most likely to have produced this?
  </div>

  <div class="algorithm">
    <b>Forward Algorithm (Computing Likelihood):</b>
    <br><br>
    Define: <code>α_t(i) = P(O_1, O_2, ..., O_t, q_t = i | λ)</code>
    <br>
    "Probability of seeing observations up to time t AND being in state i at time t"
    <br><br>
    <b>Recursion:</b>
    <br>
    <code>α_t(j) = [ Σ_i α_{t-1}(i) * A_{ij} ] * B_j(O_t)</code>
    <br><br>
    <b>What it means:</b>
    <ul>
      <li>Sum up all ways to reach state j from any previous state i.</li>
      <li>Weight each path by transition probability A_{ij}.</li>
      <li>Multiply by the probability that state j emits the current observation O_t.</li>
    </ul>
    <br>
    <b>Final answer:</b> <code>P(O | λ) = Σ_i α_T(i)</code>
  </div>

  <div class="example">
    <b>Simple Example:</b>
    <br><br>
    Two states, observe sequence [symbol_1, symbol_2].
    <ul>
      <li><code>α_1(1) = π_1 * B_1(symbol_1)</code> — prob of starting in state 1 AND emitting symbol_1</li>
      <li><code>α_1(2) = π_2 * B_2(symbol_1)</code> — prob of starting in state 2 AND emitting symbol_1</li>
      <li><code>α_2(1) = [α_1(1)*A_11 + α_1(2)*A_21] * B_1(symbol_2)</code> — all ways to reach state 1 at time 2</li>
      <li><code>α_2(2) = [α_1(1)*A_12 + α_1(2)*A_22] * B_2(symbol_2)</code></li>
      <li><code>P(sequence) = α_2(1) + α_2(2)</code></li>
    </ul>
  </div>

  <h3>2.2 Problem 2: Decoding (Viterbi Algorithm)</h3>
  <div class="concept">
    <b>Question:</b> Given an HMM and an observation sequence, what is the most likely sequence of hidden states?
    <br><br>
    <b>Application:</b> Alignment. You observed codebook symbols; what path through the hidden states was most likely? (Useful for debugging or understanding what the model "thinks.")
  </div>

  <div class="algorithm">
    <b>Viterbi Algorithm (Finding Best Path):</b>
    <br><br>
    Define: <code>δ_t(i) = max probability of best path to state i at time t</code>
    <br><br>
    <b>Recursion:</b>
    <br>
    <code>δ_t(j) = max_i [ δ_{t-1}(i) * A_{ij} ] * B_j(O_t)</code>
    <br><br>
    <b>Backtracking:</b> Keep track of which state i gave the max for each j, t. Then trace back from the end to reconstruct the path.
  </div>

  <h3>2.3 Problem 3: Learning (Baum-Welch Algorithm) ⭐</h3>
  <div class="concept">
    <b>Question:</b> Given observation sequences (training data), find the HMM parameters (π, A, B) that best explain the data.
    <br><br>
    <b>Application:</b> Training. This is what we do in this project to learn digit models!
    <br><br>
    <b>Why is it hard?</b> We don't know the true hidden state sequence — we only see observations. If we knew the states, it would be easy (just count). But states are hidden.
  </div>

  <!-- ==================== PART 3: BAUM-WELCH ==================== -->
  <h2>Part 3: Baum-Welch Algorithm (In Depth)</h2>

  <h3>3.1 The Big Idea: Expectation-Maximization</h3>
  <div class="concept">
    <b>Baum-Welch is a special case of Expectation-Maximization (EM).</b>
    <br><br>
    The idea:
    <ol>
      <li><b>E-step (Expectation):</b> Assume current HMM parameters. Compute probability of being in each state at each time (even though we don't observe the states).</li>
      <li><b>M-step (Maximization):</b> Use those probabilities to re-estimate the parameters.</li>
      <li><b>Repeat:</b> Keep going until parameters converge (stop changing).</li>
    </ol>
    <br>
    <b>Why it works:</b> Each iteration improves (or keeps the same) the likelihood of the training data. Eventually you reach a local maximum.
  </div>

  <h3>3.2 Forward and Backward Passes</h3>
  <div class="concept">
    <b>Forward Pass:</b> Compute α_t(i) (done above with Forward Algorithm).
    <br><br>
    <b>Backward Pass:</b> Compute β_t(i) "going backwards in time".
    <br><br>
    Define: <code>β_t(i) = P(O_{t+1}, O_{t+2}, ..., O_T | q_t = i, λ)</code>
    <br>
    "Probability of seeing the rest of observations GIVEN we are in state i at time t"
    <br><br>
    <b>Backward Recursion:</b>
    <br>
    <code>β_t(i) = Σ_j A_{ij} * B_j(O_{t+1}) * β_{t+1}(j)</code>
    <br>
    <code>β_T(i) = 1</code> for all i (at the end, everything is "seen")
  </div>

  <div class="example">
    <b>Intuition:</b>
    <br>
    Forward α gives you: "probability of observations so far and being here"
    <br>
    Backward β gives you: "probability of observations to come given we are here"
    <br>
    Together: α_t(i) * β_t(i) ∝ P(being in state i at time t | all observations)
  </div>

  <h3>3.3 Computing State Probabilities</h3>
  <div class="concept">
    Once you have α and β, compute:
    <br><br>
    <b>γ_t(i):</b> Probability of being in state i at time t
    <br>
    <code>γ_t(i) = (α_t(i) * β_t(i)) / Σ_j (α_t(j) * β_t(j))</code>
    <br><br>
    <b>ξ_t(i,j):</b> Probability of transition from state i to j at time t
    <br>
    <code>ξ_t(i,j) = (α_t(i) * A_{ij} * B_j(O_{t+1}) * β_{t+1}(j)) / P(O|λ)</code>
    <br><br>
    These are the "expected counts" — how many times we expect to be in each state, how many times we expect each transition.
  </div>

  <h3>3.4 Re-estimating Parameters</h3>
  <div class="concept">
    <b>New π (initial state probability):</b>
    <br>
    <code>π_i_new = γ_1(i)</code>
    <br>
    "What's the expected state at time 1?"
    <br><br>
    <b>New A (transition matrix):</b>
    <br>
    <code>A_ij_new = (Σ_t ξ_t(i,j)) / (Σ_t Σ_k ξ_t(i,k))</code>
    <br>
    "Expected transitions i→j / total transitions from i"
    <br><br>
    <b>New B (emission matrix):</b>
    <br>
    <code>B_j(k)_new = (Σ_t [γ_t(j) if O_t == k]) / (Σ_t γ_t(j))</code>
    <br>
    "Expected times state j emits symbol k / total expected time in state j"
  </div>

  <h3>3.5 Algorithm Pseudocode</h3>
  <div class="algorithm">
    <code>
BAUM-WELCH(O, initial_λ, num_iterations):
  λ ← initial_λ
  for iter = 1 to num_iterations:
    for each training sequence O:
      // E-step: compute α and β
      α ← FORWARD(O, λ)
      β ← BACKWARD(O, λ)
      
      // Compute γ and ξ
      for t = 1 to T:
        γ_t ← (α_t * β_t) / P(O|λ)
        ξ_t ← (α_t * A * B_diag(O_{t+1}) * β_{t+1}) / P(O|λ)
      
      // M-step: re-estimate parameters
      accumulate γ and ξ statistics
    
    // Update λ based on accumulated statistics
    π_new ← average γ_1 across all sequences
    A_new ← compute from Σξ statistics
    B_new ← compute from γ statistics
    
    if ||λ_new - λ|| < threshold:
      break  // converged
    λ ← λ_new
  
  return λ
    </code>
  </div>

  <!-- ==================== PART 4: IN THIS PROJECT ==================== -->
  <h2>Part 4: How Baum-Welch is Used Here</h2>

  <h3>4.1 Project Setup</h3>
  <div class="concept">
    <b>Training Phase:</b>
    <ul>
      <li>For each digit (2, 3, 4, 5), we have training sequences (MFCC frames quantized to codebook symbols).</li>
      <li>Initialize one HMM per digit with random or uniform parameters.</li>
      <li>Run Baum-Welch for ~20 iterations per digit.</li>
      <li>Result: 4 trained HMMs (one per digit).</li>
    </ul>
    <br>
    <b>Testing Phase:</b>
    <ul>
      <li>For a new audio sample, extract MFCC and quantize to codebook symbols.</li>
      <li>Compute P(observation | HMM_2), P(observation | HMM_3), P(observation | HMM_4), P(observation | HMM_5).</li>
      <li>Pick the HMM with highest probability → that's your predicted digit.</li>
    </ul>
  </div>

  <h3>4.2 Main Methods & What They Do</h3>
  <div class="concept">
    <b>hmm_forward():</b> Computes the forward probabilities (α values) for a sequence. Used to determine how likely the HMM is to produce a given observation sequence. Essential for both training and classification.
    <br><br>
    <b>hmm_backward():</b> Computes the backward probabilities (β values) going in reverse through the sequence. Combined with forward probabilities, it tells us the probability of being in each state at each time step. Only used during training.
    <br><br>
    <b>hmm_train():</b> The main Baum-Welch loop. Iterates multiple times, each iteration: runs forward-backward, computes expected state visits and transitions, updates all HMM parameters (π, A, B). Stops when parameters converge or max iterations reached.
    <br><br>
    <b>hmm_forward_likelihood():</b> Wrapper that runs the forward algorithm and returns the final probability P(observations | HMM). Used for classification to score how well each digit's HMM explains the test observation.
    <br><br>
    <b>hmm_classify():</b> Takes a test sequence, computes its likelihood under each digit's HMM, returns the digit with highest likelihood.
  </div>

  <h3>4.3 Parameters Used</h3>
  <div class="concept">
    <b>N = 5:</b> Number of hidden states per digit. (Why 5? It's a common choice. More states = more flexibility but needs more training data. 5 is reasonable for digits.)
    <br><br>
    <b>M = 32:</b> Codebook size (after k-means quantization). Each frame becomes one of 32 symbols.
    <br><br>
    <b>T (sequence length):</b> Varies per training sequence. Typically 10–200 frames per digit sample.
    <br><br>
    <b>Iterations:</b> ~20 Baum-Welch iterations per digit. Usually converges faster.
  </div>

  <!-- ==================== PART 5: PRACTICAL INTUITION ==================== -->
  <h2>Part 5: Practical Intuition & Common Questions</h2>

  <h3>5.1 Why Does Baum-Welch Work?</h3>
  <div class="example">
    <b>Think of it like this:</b> You're a detective trying to figure out what happened at a crime scene, but you only have indirect clues.
    <br><br>
    <b>Observation:</b> "Person said 'three'" (the audio you observe).
    <br><br>
    <b>Hidden facts:</b> Where did their mouth move? How did their vocal cords vibrate? (Hidden states).
    <br><br>
    <b>Baum-Welch:</b> Starting with a guess about these hidden facts, it:
    <ol>
      <li>Computes how likely each hidden sequence is given the guess.</li>
      <li>Updates the guess to better match what you'd expect from "three".</li>
      <li>Repeats until the model is very confident.</li>
    </ol>
  </div>

  <h3>5.2 Why Do We Need Forward AND Backward?</h3>
  <div class="concept">
    <b>Forward (α):</b> "What's the probability of everything before and up to now?"
    <br>
    <b>Backward (β):</b> "What's the probability of everything after now?"
    <br><br>
    Together, they tell you: "Given all the data, how sure am I about being in this state right now?"
    <br><br>
    If you only had Forward, you'd ignore half the information (the future observations).
  </div>

  <h3>5.3 Numerical Stability Issues</h3>
  <div class="warning">
    <b>Problem:</b> Probabilities are very small (0.0001 × 0.00001 × ...). You get underflow (numbers round to 0).
    <br><br>
    <b>Solution (Log-Space):</b> Work with logarithms.
    <br>
    <code>log(A × B) = log(A) + log(B)</code>
    <br>
    <code>log(A / B) = log(A) - log(B)</code>
    <br><br>
    The code in <code>hmm.c</code> uses log probabilities (log-likelihood) to avoid underflow.
  </div>

  <h3>5.4 Why Not Initialize with All Zeros?</h3>
  <div class="concept">
    <b>Bad initialization:</b> If π = [0, 0, 1, 0, 0], the algorithm will never explore other states (symmetry breaks).
    <br><br>
    <b>Good initialization:</b> Small random values or uniform. This lets the algorithm search the full space and converge to a good solution.
  </div>

  <!-- ==================== PART 6: SUMMARY ==================== -->
  <h2>Part 6: Summary & Key Takeaways</h2>

  <div class="concept">
    <b>HMM:</b> A statistical model with hidden states that emit observations. Defined by N, M, π, A, B.
    <br><br>
    <b>Evaluation (Forward):</b> Compute P(observations | HMM). Used for classification.
    <br><br>
    <b>Decoding (Viterbi):</b> Find most likely hidden state sequence. Used for alignment.
    <br><br>
    <b>Learning (Baum-Welch):</b> Estimate HMM parameters from data. Uses forward-backward algorithm + re-estimation.
    <br><br>
    <b>In this project:</b> We use Baum-Welch to train HMMs for each digit, then classify new samples by picking the HMM with highest likelihood.
  </div>

  <div class="step">
    <b>Next Steps:</b>
    <ul>
      <li>Read <a href="hmm_c.html">hmm.c line-by-line</a> to see the implementation.</li>
      <li>Check <a href="parameters.html">Parameters Explained</a> for why we chose N=5, M=32, etc.</li>
      <li>Try the <a href="tutorial.html">Step-by-step Tutorial</a> to run the code.</li>
      <li>See <a href="math_appendix.html">Math Appendix</a> for detailed derivations.</li>
    </ul>
  </div>

  <div class="footer">Questions? Check <a href="glossary.html">Glossary</a> for term definitions.</div>
</div>
</body>
</html>
